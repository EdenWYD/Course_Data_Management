{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 03 - Due Monday, November 19 at 1pm\n",
    "\n",
    "*Objectives*: Use Spark to process and perform basic analysis on non-relational data, including its DataFrame and SQL interfaces.\n",
    "\n",
    "*Grading criteria*: The tasks should all be completed, and questions should all be answered with Python code, SQL queries, shell commands, and markdown cells.  The notebook itself should be completely reproducible (using AWS EC2 instance based on the provided AMI) from start to finish; another person should be able to use the code to obtain the same results as yours.  Note that you will receive no more than partial credit if you do not add text/markdown cells explaining your thinking when appropriate.\n",
    "\n",
    "*Attestation*: **Work in groups**.  At the end of your submitted notebook, identify the work each partner performed and attest that each contributed substantially to the work.\n",
    "\n",
    "*Deadline*: Monday, November 19, 1pm.  One member of each group must submit your notebook to Blackboard; you should not submit it separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Setup\n",
    "\n",
    "Begin by setting up Spark and fetching the project data.  \n",
    "\n",
    "**Note**: you may want to use a larger EC2 instance type than normal.  This project was prepared using a `t2.xlarge` instance.  Just remember that the larger the instance, the higher the per-hour charge, so be sure to remember to shut your instance down when you're done, as always.\n",
    "\n",
    "### About the data\n",
    "\n",
    "We will use JSON data from Twitter; we saw an example of this in class.  It should parse cleanly, allowing you to focus on analysis.\n",
    "\n",
    "This data was gathered using GWU Libraries' [Social Feed Manager](http://sfm.library.gwu.edu/) application during a recent game of the MLB World Series featuring the Los Angeles Dodgers and Boston Red Sox.  This first file tells you a little bit about how it was gathered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/2018-dmfa/project-3/ea26ccd641744d4a8dce84de0785186d-README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ea26ccd641744d4a8dce84de0785186d-README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important pieces in that metadata are:\n",
    "\n",
    " * It tracked tweets that mentioned \"dodgers\" or \"redsox\" and several additional related terms.  Every item in this set should refer to one or more of these terms.\n",
    " * This data was deduplicated; we should not see individual tweets more than once.\n",
    " * Data was collected between October 23 and October 30.  All five games of the Series were played during this time.\n",
    " \n",
    "You should not need to know anything about baseball to complete this assignment, but if you have baseball questions (or Twitter questions!) please ask on the discussion forum.\n",
    "\n",
    "**Please note**: sometimes social media data contains offensive material.  This data set has not been filtered; if you do come across something inappropriate, please do your best to ignore it if you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data\n",
    "\n",
    "The following files are available:\n",
    "\n",
    " * https://s3.amazonaws.com/2018-dmfa/project-3/ea26ccd641744d4a8dce84de0785186d_009.json\n",
    " * https://s3.amazonaws.com/2018-dmfa/project-3/ea26ccd641744d4a8dce84de0785186d_010.json\n",
    " * https://s3.amazonaws.com/2018-dmfa/project-3/ea26ccd641744d4a8dce84de0785186d_011.json\n",
    " * https://s3.amazonaws.com/2018-dmfa/project-3/ea26ccd641744d4a8dce84de0785186d_012.json\n",
    " \n",
    "### Q1.1 - Select at least one and obtain it using `wget`.  Verify the file sizes using the command line.\n",
    "\n",
    "Each file should contain exactly 100,000 tweets.  \n",
    "\n",
    "*Note*: you are only required to use one of these files, but you may use more than one.  It will be easier to process more data if you use a larger EC2 instance type, as suggested above.  Use the exact same set of files throughout the assignment.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your reference, here is the text of one Tweet, randomly selected from one of these files.  You might wish to study its structure and refer to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat *.json | shuf -n 1 > example-tweet.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(json.load(open(\"example-tweet.json\")), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find several key elements in this example; the text, time, and language of the tweet, whether it was a reply to another user, the user's screen name along with their primary language and other account information like creation date, follower/friend/tweet counts, and perhaps their location.  If there are hashtags, user mentions, or urls present in their tweet, they will be present in the `entities` section; these are not present in every tweet.  If this is a retweet, you will see the original tweet and its information nested within."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 - Start up Spark, and verify the file sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use our normal startup sequence here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkContext(appName='project-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlc = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = sqlc.read.json(\"ea26ccd6*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that Spark has loaded the same number of tweets you saw before:\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell with your verification code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Comparing DataFrames and Spark SQL\n",
    "\n",
    "For the next three questions, we will look at operations using both DataFrames and SQL queries. Note that `tweets` is already a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To issue SQL queries, we need to register a table based on `tweets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.createOrReplaceTempView(\"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 - Which 10 languages are most commonly used in tweets?  Verify your result by executing it with both the dataframe and with SQL.\n",
    "\n",
    "Hint: for the dataframe, use `groupBy`, `count`, and `orderBy`.  See the documentation at https://spark.apache.org/docs/2.3.1/api/python/pyspark.sql.html for details on these and other functions.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 - Which 10 time zones are most common among users?  Verify your result with both the dataframe and SQL.\n",
    "\n",
    "*Note*: for this question, you may leave NULL values present in your results, as a way to help you understand what data is present and what is missing.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 - How many tweets mention the Dodgers?  How many mention the Red Sox?  How many mention both?\n",
    "\n",
    "You may use either the dataframe or SQL to answer.  Explain why you have chosen that approach.\n",
    "\n",
    "Hint:  you will want to look at the value of the `text` field.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - More complex queries\n",
    "\n",
    "For this section, you may choose to use dataframe queries or SQL.  If you wish, you may verify results by using both, as in Part 2, but this is not required for this section.\n",
    "\n",
    "### Q3.1 - Team mentions by location\n",
    "\n",
    "In which users' locations are the Red Sox and the Dodgers being mentioned the most?  Consider each team separately, one at a time.  Discuss your findings.\n",
    "\n",
    "Hint:  you may use either the time zones or user-specified locations for this question.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2 - Which Twitter users are being replied to the most?\n",
    "\n",
    "Discuss your findings.\n",
    "\n",
    "Hint: use the top-level `in_reply_to_screen_name` for this.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3 - Which 10 verified users have the most followers?  Which 10 unverified users have the most followers?\n",
    "\n",
    "Provide both the screen names and follower counts for each.\n",
    "\n",
    "Discuss your findings.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.4 - What are the most popular sets of hashtags among users with many followers?  Are they the same as among users with few followers?\n",
    "\n",
    "Decide for yourself exactly how many followers you believe to be \"many\", and explain your decision.  You may use queries and statistics to support this decision if you wish.\n",
    "\n",
    "Hint: if your sample tweet above does not include hashtags under the `entities` field, generate a new example by running the `shuf` command again until you find one that does.\n",
    "\n",
    "Hint 2: the hashtag texts will be in an array, so you may need some functions you haven't used before.  If you're using SQL, see the docs for [Hive SQL](https://docs.treasuredata.com/articles/hive-functions) for details, (and consider `CONCAT_WS`, for example).\n",
    "\n",
    "Discuss your findings.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.5 - Analyze common words in tweet text\n",
    "\n",
    "Following the example in class, use `tweets.rdd` to find the most common interesting words in tweet text.  To keep it \"interesting\", add a filter that removes at least 10 common stop words found in tweets, like \"a\", \"an\", \"the\", and \"RT\" (you might want to derive these stop words from initial results).  To split lines into words, a simple split on text whitespace like we had in class is sufficient; you do not have to account for punctuation.\n",
    "\n",
    "After you find the most common words, use dataframe or SQL queries to find patterns among how those words are used.  For example, are they more frequently used by Dodgers or Red Sox fans, or by people in one part of the country over another?  Explore and see what you can find, and discuss your findings.\n",
    "\n",
    "Hint: don't forget all the word count pipeline steps we used earlier in class.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
